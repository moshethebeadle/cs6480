{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Jacob (Jake) Toronto\n",
    "\n",
    "10991530\n",
    "\n",
    "Spring 2024\n",
    "\n",
    "CS 6480 Advanced Machine Learning\n",
    "\n",
    "Dr. Larry Zeng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, I use Gradient Descent to calculate the weights and biases of the neural network in Assignment 1 (which represents the XOR function).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "First, we show the formulas that define the network.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "The inputs are $x_1$ and $x_2$.  They are real-valued.\n",
    "\n",
    "First we convert these to binary:\n",
    "\n",
    "$$u_1 = step(x_1)$$\n",
    "\n",
    "$$u_2 = step(x_2)$$\n",
    "\n",
    "### Middle Layer\n",
    "\n",
    "$$v_1 = \\sigma(u_1 * w_1 + u_2 * w_2 + b_1)$$\n",
    "\n",
    "$$v_2 = \\sigma(u_1 * w_3 + u_2 * w_4 + b_2)$$\n",
    "\n",
    "\n",
    "### Output Layer\n",
    "\n",
    "$$\\hat{z} = \\sigma(v_1 * w_5 + v_2 * w+6 + b_3)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives\n",
    "\n",
    "Here are the derivatives:\n",
    "\n",
    "### middle-top layer\n",
    "$$\\frac{dz}{w_{1}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * w_{5} * v_{1} * (1 - v_{1}) * u_{1}$$\n",
    "$$\\frac{dz}{w_{2}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * w_{5} * v_{1} * (1 - v_{1}) * u_{2}$$\n",
    "$$\\frac{dz}{b_{1}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * w_{5} * v_{1} * (1 - v_{1}) * 1$$\n",
    "\n",
    "### middle-bottom layer\n",
    "$$\\frac{dz}{w_{3}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * w_{6} * v_{2} * (1 - v_{2}) * u_{1}$$\n",
    "$$\\frac{dz}{w_{4}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * w_{6} * v_{2} * (1 - v_{2}) * u_{2}$$\n",
    "$$\\frac{dz}{b_{2}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * w_{6} * v_{2} * (1 - v_{2}) * 1$$\n",
    "\n",
    "### outer layer\n",
    "$$\\frac{dz}{w_{5}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * v_{1}$$\n",
    "$$\\frac{dz}{w_{6}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * v_{2}$$\n",
    "$$\\frac{dz}{b_{3}} = (\\hat{z} - z) * \\hat{z} * (1 - \\hat{z}) * 1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Here I run the gradient descent algorithm, updating each weight and bias using the derivative.\n",
    "\n",
    "This approach is Stochastic, not Batch: we iterate over each row one at a time and update the weights on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1 0 0.8 0.8 0.63 {'w1': 0.0, 'w2': 0.8, 'b1': 0.3, 'w3': 0.4, 'w4': 0.9, 'b2': 0.9, 'w5': 0.9, 'w6': 0.4, 'b3': 0.3}\n",
      "999 1 1 0 0.52 0.52 0.27 {'w1': 0.3, 'w2': 0.7, 'b1': 0.3, 'w3': 0.4, 'w4': 0.9, 'b2': 0.9, 'w5': 0.5, 'w6': 0.1, 'b3': -0.4}\n",
      "1998 1 1 0 0.54 0.54 0.29 {'w1': 0.6, 'w2': 0.9, 'b1': 0.3, 'w3': 0.6, 'w4': 1.0, 'b2': 0.9, 'w5': 0.5, 'w6': 0.3, 'b3': -0.6}\n",
      "2997 1 1 0 0.56 0.56 0.32 {'w1': 1.3, 'w2': 1.4, 'b1': 0.4, 'w3': 0.9, 'w4': 1.1, 'b2': 0.8, 'w5': 0.9, 'w6': 0.4, 'b3': -1.1}\n",
      "3996 1 1 0 0.63 0.63 0.39 {'w1': 2.6, 'w2': 2.6, 'b1': -0.1, 'w3': 1.2, 'w4': 1.4, 'b2': 0.8, 'w5': 2.1, 'w6': 0.3, 'b3': -1.9}\n",
      "4995 1 1 0 0.66 0.66 0.43 {'w1': 3.8, 'w2': 3.9, 'b1': -0.6, 'w3': 1.2, 'w4': 1.4, 'b2': 0.7, 'w5': 3.4, 'w6': -0.4, 'b3': -2.4}\n",
      "5994 1 1 0 0.61 0.61 0.37 {'w1': 4.6, 'w2': 4.7, 'b1': -0.8, 'w3': 0.9, 'w4': 1.1, 'b2': -0.3, 'w5': 4.3, 'w6': -1.6, 'b3': -2.5}\n",
      "6993 1 1 0 0.3 0.3 0.09 {'w1': 5.2, 'w2': 5.2, 'b1': -1.4, 'w3': 2.1, 'w4': 2.1, 'b2': -3.0, 'w5': 5.3, 'w6': -4.6, 'b3': -2.6}\n",
      "7992 1 1 0 0.15 0.15 0.02 {'w1': 5.5, 'w2': 5.5, 'b1': -1.9, 'w3': 2.9, 'w4': 2.9, 'b2': -4.3, 'w5': 6.1, 'w6': -6.2, 'b3': -2.8}\n",
      "8991 1 1 0 0.1 0.1 0.01 {'w1': 5.7, 'w2': 5.7, 'b1': -2.1, 'w3': 3.2, 'w4': 3.2, 'b2': -4.9, 'w5': 6.6, 'w6': -7.0, 'b3': -3.0}\n",
      "9990 1 1 0 0.08 0.08 0.01 {'w1': 5.8, 'w2': 5.8, 'b1': -2.3, 'w3': 3.4, 'w4': 3.4, 'b2': -5.2, 'w5': 7.0, 'w6': -7.4, 'b3': -3.2}\n",
      "10989 1 1 0 0.07 0.07 0.0 {'w1': 5.9, 'w2': 5.9, 'b1': -2.3, 'w3': 3.6, 'w4': 3.6, 'b2': -5.4, 'w5': 7.2, 'w6': -7.8, 'b3': -3.3}\n",
      "11988 1 1 0 0.06 0.06 0.0 {'w1': 5.9, 'w2': 5.9, 'b1': -2.4, 'w3': 3.7, 'w4': 3.7, 'b2': -5.6, 'w5': 7.4, 'w6': -8.0, 'b3': -3.4}\n",
      "12987 1 1 0 0.05 0.05 0.0 {'w1': 6.0, 'w2': 6.0, 'b1': -2.5, 'w3': 3.8, 'w4': 3.8, 'b2': -5.7, 'w5': 7.6, 'w6': -8.2, 'b3': -3.5}\n",
      "13986 1 1 0 0.05 0.05 0.0 {'w1': 6.0, 'w2': 6.0, 'b1': -2.5, 'w3': 3.8, 'w4': 3.8, 'b2': -5.8, 'w5': 7.8, 'w6': -8.4, 'b3': -3.5}\n",
      "14985 1 1 0 0.05 0.05 0.0 {'w1': 6.1, 'w2': 6.1, 'b1': -2.5, 'w3': 3.9, 'w4': 3.9, 'b2': -5.9, 'w5': 7.9, 'w6': -8.5, 'b3': -3.6}\n",
      "15984 1 1 0 0.04 0.04 0.0 {'w1': 6.1, 'w2': 6.1, 'b1': -2.6, 'w3': 3.9, 'w4': 3.9, 'b2': -6.0, 'w5': 8.0, 'w6': -8.6, 'b3': -3.6}\n",
      "16983 1 1 0 0.04 0.04 0.0 {'w1': 6.1, 'w2': 6.2, 'b1': -2.6, 'w3': 4.0, 'w4': 4.0, 'b2': -6.1, 'w5': 8.1, 'w6': -8.8, 'b3': -3.7}\n",
      "17982 1 1 0 0.04 0.04 0.0 {'w1': 6.2, 'w2': 6.2, 'b1': -2.6, 'w3': 4.0, 'w4': 4.0, 'b2': -6.2, 'w5': 8.2, 'w6': -8.9, 'b3': -3.7}\n",
      "18981 1 1 0 0.04 0.04 0.0 {'w1': 6.2, 'w2': 6.2, 'b1': -2.6, 'w3': 4.1, 'w4': 4.1, 'b2': -6.2, 'w5': 8.3, 'w6': -9.0, 'b3': -3.8}\n",
      "19980 1 1 0 0.03 0.03 0.0 {'w1': 6.2, 'w2': 6.2, 'b1': -2.7, 'w3': 4.1, 'w4': 4.1, 'b2': -6.3, 'w5': 8.4, 'w6': -9.0, 'b3': -3.8}\n",
      "{'w1': 6.2, 'w2': 6.2, 'b1': -2.7, 'w3': 4.1, 'w4': 4.1, 'b2': -6.3, 'w5': 8.4, 'w6': -9.0, 'b3': -3.8}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "u1_all = [0, 0, 1, 1]\n",
    "u2_all = [0, 1, 0, 1]\n",
    "zt_all = [0, 1, 1, 0]\n",
    "\n",
    "import random as r\n",
    "w1 = r.random()\n",
    "w2 = r.random()\n",
    "b1 = r.random()\n",
    "w3 = r.random()\n",
    "w4 = r.random()\n",
    "b2 = r.random()\n",
    "w5 = r.random()\n",
    "w6 = r.random()\n",
    "b3 = r.random()\n",
    "things = [w1, w2, b1, w3, w4, b2, w5, w6, b3]\n",
    "\n",
    "import math \n",
    "\n",
    "def s(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def results():\n",
    "  return {\n",
    "    \"w1\": w1,\n",
    "    \"w2\": w2,\n",
    "    \"b1\": b1,\n",
    "    \"w3\": w3,\n",
    "    \"w4\": w4,\n",
    "    \"b2\": b2,\n",
    "    \"w5\": w5,\n",
    "    \"w6\": w6,\n",
    "    \"b3\": b3\n",
    "  }\n",
    "\n",
    "epochs = 20000\n",
    "learning_rate = 0.1\n",
    "for i in range(epochs):\n",
    "    for u1, u2, zt in zip(u1_all, u2_all, zt_all):\n",
    "        \n",
    "        # build up the components of the network\n",
    "\n",
    "        # first layer\n",
    "        v1 = s(w1*u1 + w2*u2 + b1)\n",
    "        v2 = s(w3*u1 + w4*u2 + b2)\n",
    "\n",
    "        # output (z-hat or z-predicted)\n",
    "        zp = s(w5*v1 + w6*v2 + b3)\n",
    "\n",
    "        raw_loss = zp - zt\n",
    "        \n",
    "        # base gradient\n",
    "        dz = raw_loss * zp * (1 - zp)\n",
    "\n",
    "        # middle top\n",
    "        top_grad = dz * w5 * v1 * (1 - v1)\n",
    "        w1 -= learning_rate * top_grad * u1\n",
    "        w2 -= learning_rate * top_grad * u2\n",
    "        b1 -= learning_rate * top_grad\n",
    "\n",
    "        # middle bottom\n",
    "        bot_grad = dz * w6 * v2 * (1 - v2)\n",
    "        w3 -= learning_rate * bot_grad * u1\n",
    "        w4 -= learning_rate * bot_grad * u2\n",
    "        b2 -= learning_rate * bot_grad\n",
    "\n",
    "        # outer layer adjustments\n",
    "        w5 -= learning_rate * dz * v1\n",
    "        w6 -= learning_rate * dz * v2\n",
    "        b3 -= learning_rate * dz\n",
    "\n",
    "    if i % 999 == 0:\n",
    "      print(i, u1, u2, zt, round(zp, 2), round(raw_loss, 2), round(raw_loss**2,2), {k: round(v, 1) for k, v in results().items()})\n",
    "print({k: round(v, 1) for k, v in results().items()})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "I used `20,000` epochs to train the weights.\n",
    "\n",
    "In this case, the error was at `0.0` before the 8,000-th epoch.\n",
    "\n",
    "However, in other runs, we needed more than 10,000 epochs to reach `0.0` error.\n",
    "\n",
    "That's why I chose `20,000` epochs.\n",
    "\n",
    "Each run results in different values for the weights and biases.\n",
    "\n",
    "Here are a few:\n",
    "\n",
    "```\n",
    "{'w1': 7.0, 'w2': -1.9, 'b1': 1.1, 'w3': 7.9, 'w4': 5.0, 'b2': -1.0, 'w5': -5.0, 'w6': 6.4, 'b3': -1.5}\n",
    "{'w1': 4.2, 'w2': 4.2, 'b1': -6.5, 'w3': 6.1, 'w4': 6.2, 'b2': -2.7, 'w5': -9.3, 'w6': 8.6, 'b3': -3.9}\n",
    "{'w1': 4.2, 'w2': 4.2, 'b1': -6.4, 'w3': 6.1, 'w4': 6.2, 'b2': -2.7, 'w5': -9.2, 'w6': 8.5, 'b3': -3.9}\n",
    "{'w1': 4.2, 'w2': 4.2, 'b1': -6.5, 'w3': 6.1, 'w4': 6.1, 'b2': -2.7, 'w5': -9.2, 'w6': 8.6, 'b3': -3.9}\n",
    "{'w1': 6.1, 'w2': 6.1, 'b1': -2.6, 'w3': 4.2, 'w4': 4.2, 'b2': -6.4, 'w5': 8.5, 'w6': -9.2, 'b3': -3.9}\n",
    "{'w1': 6.1, 'w2': 6.1, 'b1': -2.7, 'w3': 4.2, 'w4': 4.2, 'b2': -6.4, 'w5': 8.5, 'w6': -9.2, 'b3': -3.9}\n",
    "{'w1': 6.6, 'w2': 6.6, 'b1': -2.8, 'w3': -4.2, 'w4': -4.2, 'b2': 6.3, 'w5': 6.5, 'w6': 6.8, 'b3': -9.7}\n",
    "```\n",
    "\n",
    "As you can see, there is quite a range of options for the weights that still result in a good network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
